{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Mikolov Negatives'\n",
    "If we take the vector of king, subtract the vector of man, and add the vector of woman, how close are we to the vector of queen?\n",
    "This notebook will implement a function to allow smooth testing of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "import sentencepiece    # necessary for proper t5 init.\n",
    "from transformers import T5Tokenizer, T5EncoderModel, GPT2Tokenizer, OPTModel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# api key set in conda env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab\n",
    "Now expanded to the Oxford 5000, plus relevant test words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "with open('./expanded_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        vocab.append(line.strip())\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3\n",
    "Vectors are normalized. Produced by https://arxiv.org/abs/2201.10005. Note: \"Our models achieved new state-of-the-art results in linear-probe classification, text search and code search. We find that our models **underperformed on sentence similarity tasks and observed unexpected training behavior with respect to these tasks**.\" (emphasis mine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved embeddings from GPT-3 Curie\n",
    "# Curie embeds: 4098 dims\n",
    "ada_embeds = []\n",
    "with open(u'./gpt/gpt_curie.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        ada_embeds.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "model_gpt = dict(zip(vocab, ada_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting new embeddings from OpenAI\n",
    "def gpt_embed(text, engine='text-similarity-curie-001'):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return openai.Embedding.create(input=[text], engine=engine)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT\n",
    "OPT, like GPT-3, is a Decoder-only Transformer. BERT is encoder only, and T5 is encoder-decoder, making use of both. Likewise, getting embeddings from OPT is a *little* less complicated, as there is only one part of the architecture we look to for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/opt-13b were not used when initializing OPTModel: ['decoder.final_layer_norm.weight', 'decoder.final_layer_norm.bias']\n",
      "- This IS expected if you are initializing OPTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing OPTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# WARNING: OPT-13B uses ~49GB of RAM when loaded into memory.\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('facebook/opt-13b', cache_dir='/scratch/mbarlow6/.cache')\n",
    "model_opt_raw = OPTModel.from_pretrained('facebook/opt-13b', cache_dir='/scratch/mbarlow6/.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5120D vectors here :)\n",
    "opt_embeds = []\n",
    "with open(u'./opt/13B.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        opt_embeds.append([float(x) for x in line.strip().split()])\n",
    "model_opt = dict(zip(vocab, opt_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_embed(text, tokenizer=gpt2_tokenizer, model=model_opt_raw, debug=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    if debug:\n",
    "        print('Tokens Requested:')\n",
    "        print(tokenizer.batch_decode(inputs.input_ids[0]))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = torch.squeeze(outputs.last_hidden_state, dim=0)\n",
    "    return np.array(torch.mean(embeddings[1:], dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5\n",
    "Here is our encoder-decoder model. I will extract embeddings from the encoder only, as per results from https://arxiv.org/pdf/2108.08877.pdf. Note: \"When mean pooling is applied to the T5’s encoder outputs, it greatly outperforms the average embeddings of BERT. Notably, even without fine-tuning, the average embeddings of the T5’s encoder-only outputs outperforms SimCSE-RoBERTa, which is fine-tuned on NLI datase.\"\n",
    "\n",
    "Seeing as I amd doing no fine tuning, and mean pool OPT decoder outputs, I will do the same with T5's **encoder** outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbarlow6/.local/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-3b automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at t5-3b were not used when initializing T5EncoderModel: ['decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.final_layer_norm.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5EncoderModel were not initialized from the model checkpoint at t5-3b and are newly initialized: ['encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-3b', cache_dir='/scratch/mbarlow6/.cache')\n",
    "model_t5_raw = T5EncoderModel.from_pretrained('t5-3b', cache_dir='/scratch/mbarlow6/.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_embeds = []\n",
    "with open('./t5/t53b.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t5_embeds.append([float(x) for x in line.strip().split()])\n",
    "model_t5 = dict(zip(vocab, t5_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_embed(text, tokenizer=t5_tokenizer, model=model_t5_raw, debug=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    if debug:\n",
    "        print('Tokens Requested:')\n",
    "        print(tokenizer.batch_decode(inputs.input_ids[0]))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = torch.squeeze(outputs.last_hidden_state, dim=0)\n",
    "    return np.array(torch.mean(embeddings, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "Here I will define some functions for the purpose of the investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive(words, model='gpt'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        words: iterable\n",
    "        model: 'gpt', 'opt', or 't5'\n",
    "    Returns:\n",
    "        Positive (summed vectors) of word embeddings of a given list of words from the specified model. Defaults to GPT-3.\n",
    "    \"\"\"\n",
    "    if isinstance(words, str):\n",
    "        print(f\"You requested the positive of the string \\\"{words}\\\". Did you mean [\\\"{words}\\\"]?\")\n",
    "\n",
    "    out = 0\n",
    "    for token in words:\n",
    "        # convert token to string\n",
    "        word = str(token)\n",
    "        # do model check - least intensive operation to repeat\n",
    "        if model.lower() == 'gpt':\n",
    "            # look for token in cached GPT embeds\n",
    "            if word in model_gpt:\n",
    "                ex = model_gpt[word]  # ex for \"extracted\"\n",
    "            # if not found, query API\n",
    "            else:\n",
    "                ex = gpt_embed(word)\n",
    "                model_gpt[word] = ex\n",
    "        elif model.lower() == 'opt':\n",
    "            if word in model_opt:\n",
    "                ex = model_opt[word]\n",
    "            else:\n",
    "                # squeeze!\n",
    "                ex = opt_embed(word)\n",
    "                model_opt[word] = ex\n",
    "        elif model.lower() == 't5':\n",
    "            if word in model_t5:\n",
    "                ex = model_t5[word]\n",
    "            else:\n",
    "                ex = t5_embed(word)\n",
    "                model_t5[word] = ex\n",
    "        else:\n",
    "            raise ValueError('Please provide either gpt, opt, or t5 as a model choice.')\n",
    "\n",
    "        # construct positive\n",
    "        if isinstance(out, int):\n",
    "            out = np.array(ex).reshape(1, -1)\n",
    "        else:\n",
    "            out += np.array(ex).reshape(1, -1)\n",
    "            \n",
    "    return out if not isinstance(out, int) else np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(words, target, vec=False, model='gpt'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        words: iterable or vector   -> Items to be combined into a positive and compared,\n",
    "                                       or already constructed vector of matching dimensions.\n",
    "        target: str     -> single term to calulate similarity to.\n",
    "        vec: bool       -> true if 'words' is a vector\n",
    "        model: str      -> 'gpt', 'opt', or 't5'\n",
    "    Returns:\n",
    "        The cosine similarity of the words vector and target term in specified model.\n",
    "    \"\"\"\n",
    "    # get phrase\n",
    "    phrase = words\n",
    "    if not vec:\n",
    "        if isinstance(words, str):\n",
    "            phrase = positive([words], model)\n",
    "        else:\n",
    "            phrase = positive(words, model)\n",
    "    \n",
    "    # get target\n",
    "    target = positive([target], model)\n",
    "\n",
    "    return cosine_similarity(phrase, target)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative(start, det, add, end, model='gpt'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        start: str  -> starting word\n",
    "        det: str    -> word to subtract from start\n",
    "        add: str    -> word to add to get new direction\n",
    "        end: str    -> target word\n",
    "        model: str  -> gpt, opt, or t5.\n",
    "    Returns:\n",
    "        The cosine similarity between <end> and <start> - <det> + <add>.\n",
    "    \"\"\"\n",
    "    A = positive([start], model)\n",
    "    B = positive([det], model)\n",
    "    C = positive([add], model)\n",
    "    D = positive([end], model)\n",
    "    neg = (A - B) + C\n",
    "    return cosine_similarity(neg, D)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mikolov(start, less, more, target):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        start: str  -> starting word\n",
    "        det: str    -> word to subtract from start\n",
    "        add: str    -> word to add to get new direction\n",
    "        end: str    -> target word\n",
    "    Returns:\n",
    "        None. Wraps negative for each model we have to test.\n",
    "    \"\"\"\n",
    "    print(*[start, less, more], sep=', ', end='')\n",
    "    print(f\" -> {target}\")\n",
    "    for model in ['gpt', 'opt', 't5']:\n",
    "        print(f\"model: {model}\")\n",
    "        print(f\"score: {negative(start, less, more, model)}\")\n",
    "        print(f\"benchmark: {start} -> {target} = {calculate_similarity([start], target, model=model)}\")\n",
    "        print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "Main Categories identified: *opposite-gender*, *capitol-of*, *pluralization*, *adjective-scale*, *possesion*, and *tense*.\n",
    "\n",
    "Please refer to https://arxiv.org/pdf/1509.01692.pdf and https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/rvecs.pdf for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* opposite-gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king, man, woman -> queen\n",
      "model: gpt\n",
      "score: 0.6729880798038093\n",
      "benchmark: king -> queen = 0.8851292569413515\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6613467628491987\n",
      "benchmark: king -> queen = 0.5037397711321339\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6648142296896553\n",
      "benchmark: king -> queen = 0.3860530420267463\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('king', 'man', 'woman', 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chairman, man, woman -> chairwoman\n",
      "model: gpt\n",
      "score: 0.6193385506374722\n",
      "benchmark: chairman -> chairwoman = 0.928414866800918\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.5979181296760168\n",
      "benchmark: chairman -> chairwoman = 0.9589032532969219\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6224928570465704\n",
      "benchmark: chairman -> chairwoman = 0.48436462087132637\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('chairman', 'man', 'woman', 'chairwoman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brother, male, female -> sister\n",
      "model: gpt\n",
      "score: 0.6799844491903719\n",
      "benchmark: brother -> sister = 0.8785020289126475\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6690131338612086\n",
      "benchmark: brother -> sister = 0.4470249819252777\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6853435881126732\n",
      "benchmark: brother -> sister = 0.8213804516568233\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('brother', 'male', 'female', 'sister')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stallion, male, female -> mare\n",
      "model: gpt\n",
      "score: 0.6556616643566257\n",
      "benchmark: stallion -> mare = 0.7583042843432317\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6225629314446364\n",
      "benchmark: stallion -> mare = 0.6087521518061494\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6508969838508619\n",
      "benchmark: stallion -> mare = 0.15555480238970334\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('stallion', 'male', 'female', 'mare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* capitol-of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madrid, Spain, France -> Paris\n",
      "model: gpt\n",
      "score: 0.690129356628566\n",
      "benchmark: Madrid -> Paris = 0.8690059206865344\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6507127559965387\n",
      "benchmark: Madrid -> Paris = 0.4303607940673828\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6979207299067045\n",
      "benchmark: Madrid -> Paris = 0.6243758797645569\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('Madrid', 'Spain', 'France', 'Paris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pluralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars, car, apple -> apples\n",
      "model: gpt\n",
      "score: 0.7396348199029129\n",
      "benchmark: cars -> apples = 0.8229437328841653\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6840334182254659\n",
      "benchmark: cars -> apples = 0.139387309551239\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.712470370452123\n",
      "benchmark: cars -> apples = 0.5858688354492188\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('cars', 'car', 'apple', 'apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years, year, law -> laws\n",
      "model: gpt\n",
      "score: 0.672309158607031\n",
      "benchmark: years -> laws = 0.8118192521108692\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6892114445466884\n",
      "benchmark: years -> laws = 0.9065991640090942\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6708920462923322\n",
      "benchmark: years -> laws = 0.44145113229751587\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('years', 'year', 'law', 'laws')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* adjective-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot, warm, cool -> cold\n",
      "model: gpt\n",
      "score: 0.6799035471122096\n",
      "benchmark: hot -> cold = 0.8094623865808173\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.684984178459188\n",
      "benchmark: hot -> cold = 0.927157890849394\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6959157535214271\n",
      "benchmark: hot -> cold = 0.5191256564414523\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('hot', 'warm', 'cool', 'cold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best, good, bad -> worst\n",
      "model: gpt\n",
      "score: 0.6840402511513165\n",
      "benchmark: best -> worst = 0.8453496084889025\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7167266803741168\n",
      "benchmark: best -> worst = 0.9662132245608877\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6998340678906982\n",
      "benchmark: best -> worst = 0.5163130997210805\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('best', 'good', 'bad', 'worst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* possession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city's, city, bank -> bank's\n",
      "model: gpt\n",
      "score: 0.7539958149021666\n",
      "benchmark: city's -> bank's = 0.8545013438681033\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7310323207299744\n",
      "benchmark: city's -> bank's = 0.7009552717208862\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7341099190526892\n",
      "benchmark: city's -> bank's = 0.7618241310119629\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('city\\'s', 'city', 'bank', 'bank\\'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine, me, you -> yours\n",
      "model: gpt\n",
      "score: 0.7058381934793133\n",
      "benchmark: mine -> yours = 0.9051090576935131\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6899145928208112\n",
      "benchmark: mine -> yours = 0.47416482359328005\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6911763131105917\n",
      "benchmark: mine -> yours = 0.3430048608756724\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('mine', 'me', 'you', 'yours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* verb-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walking, legs, teeth -> chewing\n",
      "model: gpt\n",
      "score: 0.6499564519125616\n",
      "benchmark: walking -> chewing = 0.7993996582106503\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6117839805130452\n",
      "benchmark: walking -> chewing = 0.4678374320452787\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.647341491590882\n",
      "benchmark: walking -> chewing = 0.2289078643794683\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('walking', 'legs', 'teeth', 'chewing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk, legs, teeth -> chew\n",
      "model: gpt\n",
      "score: 0.6553762415589696\n",
      "benchmark: walk -> chew = 0.784419188617846\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6450453502361564\n",
      "benchmark: walk -> chew = 0.47490602590411346\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6540647831609678\n",
      "benchmark: walk -> chew = 0.3189265948477693\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('walk', 'legs', 'teeth', 'chew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sailing, boat, car -> driving\n",
      "model: gpt\n",
      "score: 0.6952303539774101\n",
      "benchmark: sailing -> driving = 0.8182398689225385\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.6743034696965616\n",
      "benchmark: sailing -> driving = 0.40121005002385757\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6944079497787948\n",
      "benchmark: sailing -> driving = 0.5557397781760884\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('sailing', 'boat', 'car', 'driving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sail, boat, car -> drive\n",
      "model: gpt\n",
      "score: 0.6947248628853393\n",
      "benchmark: sail -> drive = 0.8023252530187783\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7073158600982759\n",
      "benchmark: sail -> drive = 0.4122551928759718\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7067052875915694\n",
      "benchmark: sail -> drive = 0.3872744165407898\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('sail', 'boat', 'car', 'drive')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a58f2b50cba0e3ef60ddaac0060fcc6c1f1afd3fbbcd44f07b68475f7ee4549"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('aca': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50d097db58378ea4fc243263c82ac89485e39b9e188e1c6006c60e88b9913d6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
