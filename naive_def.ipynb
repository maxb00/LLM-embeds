{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For getting Naive definitons with Curie\n",
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# api key set in conda env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Cache\n",
    "Just GPT-3 Curie this time :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load vocabulary words\n",
    "\n",
    "vocab = []\n",
    "with open('./expanded_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        vocab.append(line.strip())\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved embeddings from GPT-3 Curie\n",
    "gpt_embeds = []\n",
    "\n",
    "with open(u'./gpt/gpt_curie.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        gpt_embeds.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "model_gpt = dict(zip(vocab, gpt_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting new embeddings from OpenAI\n",
    "def gpt_embed(text, engine='text-similarity-curie-001'):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return openai.Embedding.create(input=[text], engine=engine)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "Positive and new algorithm(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive(words):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        words: iterable\n",
    "    Returns:\n",
    "        Positive (summed vectors) of word embeddings of a given list of words.\n",
    "    \"\"\"\n",
    "    if isinstance(words, str):\n",
    "        print(f\"You requested the positive of the string \\\"{words}\\\". Did you mean [\\\"{words}\\\"]?\")\n",
    "\n",
    "    out = 0\n",
    "    for token in words:\n",
    "        # convert token to string\n",
    "        word = str(token)        \n",
    "        # look for token in cached GPT embeds\n",
    "        if word in vocab:\n",
    "            ex = model_gpt[word]  # ex for \"extracted\"\n",
    "        # if not found, query API\n",
    "        else:\n",
    "            ex = gpt_embed(word)\n",
    "            model_gpt[word] = ex\n",
    "        \n",
    "\n",
    "        # construct positive\n",
    "        if isinstance(out, int):\n",
    "            out = np.array(ex).reshape(1, -1)\n",
    "        else:\n",
    "            out += np.array(ex).reshape(1, -1)\n",
    "            \n",
    "    return out if not isinstance(out, int) else np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def naive_def(word):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        word: str   -> Single word to define\n",
    "    Returns:\n",
    "        A single tuple of words a when summed are closest to the target, not including the target.\n",
    "    \"\"\"\n",
    "    best = (None, None)\n",
    "    best_score = -1\n",
    "\n",
    "    target = positive([word])\n",
    "    for i in tqdm(range(len(vocab))):\n",
    "        w1 = vocab[i]\n",
    "        if w1 != word:\n",
    "            for w2 in vocab:\n",
    "                if w2 != word:\n",
    "                    p = positive([w1, w2])\n",
    "                    score = cosine_similarity(target, p)\n",
    "                    if score > best_score:\n",
    "                        best = (w1, w2)\n",
    "                        best_score = score\n",
    "    \n",
    "    return (best, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9cdd6602be4a7aa6f84e9484d05510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('dog', 'kitten'), array([[0.93234583]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('puppy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c6ecaade524ec491c931fd7cb452af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('kingdom', 'royal'), array([[0.94391248]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a79a36eb4d4bae9c5dddb0565f6bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('duck', 'youngster'), array([[0.92606453]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('duckling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6068da7971d4332b9180c84ed27e732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('colony', 'gun'), array([[0.88549887]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('colt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a733a0bb27c84764bb725f6969a5e803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('horse', 'pink'), array([[0.87398292]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('filly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6b9c2fcaf3434690317252d6e70282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('horse', 'puppy'), array([[0.90931456]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('foal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af82d4b3ab6c47e59b71817f487830be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('husbands', 'spouse'), array([[0.95122498]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('husband')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9e14b7411546d48b5f3bbcc7c215b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('spouse', 'wives'), array([[0.95503364]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('wife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86effa11835c4033a938484623d29a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(('democratic', 'politics'), array([[0.95029931]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_def('democracy')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a58f2b50cba0e3ef60ddaac0060fcc6c1f1afd3fbbcd44f07b68475f7ee4549"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('aca': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
