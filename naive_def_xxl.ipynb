{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For getting Naive definitons with Curie\n",
    "Includes a fully explored N^2 naive algorithm that returns the best pairing that 'defines' a single word. Revised attempt looks at less pairings, and includes a revised vocabulary to avoid plurals - in an effort to get a clean top 10 with no orthographic influences or self-referential definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# api key set in conda env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Cache\n",
    "Just GPT-3 Curie this time :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load vocabulary words\n",
    "\n",
    "vocab = []\n",
    "with open('./vocab/expanded_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        vocab.append(line.strip())\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved embeddings from GPT-3 Curie\n",
    "gpt_embeds = []\n",
    "\n",
    "with open(u'./gpt/gpt_davinci.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        gpt_embeds.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "model_gpt = dict(zip(vocab, gpt_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting new embeddings from OpenAI\n",
    "def gpt_embed(text, engine='text-similarity-davinci-001'):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return openai.Embedding.create(input=[text], engine=engine)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "Positive and new algorithm(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive(words):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        words: iterable\n",
    "    Returns:\n",
    "        Positive (summed vectors) of word embeddings of a given list of words.\n",
    "    \"\"\"\n",
    "    if isinstance(words, str):\n",
    "        print(f\"You requested the positive of the string \\\"{words}\\\". Did you mean [\\\"{words}\\\"]?\")\n",
    "\n",
    "    out = 0\n",
    "    for token in words:\n",
    "        # convert token to string\n",
    "        word = str(token)        \n",
    "        # look for token in cached GPT embeds\n",
    "        if word in vocab:\n",
    "            ex = model_gpt[word]  # ex for \"extracted\"\n",
    "        # if not found, query API\n",
    "        else:\n",
    "            ex = gpt_embed(word)\n",
    "            model_gpt[word] = ex\n",
    "        \n",
    "\n",
    "        # construct positive\n",
    "        if isinstance(out, int):\n",
    "            out = np.array(ex).reshape(1, -1)\n",
    "        else:\n",
    "            out += np.array(ex).reshape(1, -1)\n",
    "            \n",
    "    return out if not isinstance(out, int) else np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_def(word):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        word: str   -> Single word to define\n",
    "    Returns:\n",
    "        A single tuple of words a when summed are closest to the target, not including the target.\n",
    "    \"\"\"\n",
    "    best = (None, None)\n",
    "    best_score = -1\n",
    "\n",
    "    target = positive([word])\n",
    "    for i in tqdm(range(len(vocab))):\n",
    "        w1 = vocab[i]\n",
    "        if w1 != word:\n",
    "            for w2 in vocab:\n",
    "                if w2 != word:\n",
    "                    p = positive([w1, w2])\n",
    "                    score = cosine_similarity(target, p)\n",
    "                    if score > best_score:\n",
    "                        best = (w1, w2)\n",
    "                        best_score = score\n",
    "    \n",
    "    return (best, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "naive_defs are too expensive to re-run. (estimated 10h with Davinci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_def('puppy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revising our approach\n",
    "What if we want to filter for plurals and orthographic similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "\n",
    "en = inflect.engine()\n",
    "plural = en.plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess vocabulary\n",
    "helper = set(vocab)\n",
    "removed = set()\n",
    "for word in vocab:\n",
    "    # naively assume each word is singular, pluralize it\n",
    "    p = plural(word, count=2)\n",
    "    # then try and remove it from helper\n",
    "    comp = en.compare(word, p)\n",
    "    flag = str(comp)[0] != 'p' # this flags that word is a plural.\n",
    "    flag2 = p != word\n",
    "    if flag and flag2 and p in helper:\n",
    "        helper.remove(p)\n",
    "        removed.add(p)\n",
    "\n",
    "# a few words I want to keep\n",
    "removed -= set(['her', 'his', 'media', 'offspring', 'our', 'some', 'them', 'us'])\n",
    "\n",
    "len(removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revised(word, top_n=10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        word: str   -> Single word to define\n",
    "        top_n: int  -> Number of best solutions to return. Defualt 10.\n",
    "    Return:\n",
    "        N 2-word definition pairs, ordered by similarity to word.\n",
    "    \"\"\"\n",
    "    history = []\n",
    "    target = positive([word])\n",
    "    for i in tqdm(range(len(vocab))):\n",
    "        w1 = vocab[i]\n",
    "        if w1 == word:\n",
    "            continue\n",
    "        elif w1[:3] == word[:3]:\n",
    "            continue\n",
    "        elif w1 in removed:\n",
    "            continue\n",
    "        for j in range(i+1, len(vocab)):\n",
    "            w2 = vocab[j]\n",
    "            if w2 == word:\n",
    "                continue\n",
    "            elif word[:3] == w2[:3]:\n",
    "                continue\n",
    "            elif w2 in removed:\n",
    "                continue\n",
    "            p = positive([w1, w2])\n",
    "            history.append(((w1, w2), cosine_similarity(target, p)[0][0]))\n",
    "    history.sort(key=lambda x: x[1], reverse=True)\n",
    "    return history[:top_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revised Tests\n",
    "\n",
    "These do not take as long - 5 or so hours is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfea3ab941e54edd84cfd5ae6d1f17a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('husband', 'woman'), 0.9508569745697908),\n",
       " (('spouse', 'woman'), 0.9495616430191918),\n",
       " (('husband', 'spouse'), 0.9483833238064329),\n",
       " (('husband', 'mother'), 0.9430669814364032),\n",
       " (('husband', 'widow'), 0.9422477918707295),\n",
       " (('mother', 'spouse'), 0.9422354672522202),\n",
       " (('husband', 'lady'), 0.941258211067767),\n",
       " (('girlfriend', 'husband'), 0.9407533014188159),\n",
       " (('female', 'husband'), 0.9407266822454023),\n",
       " (('girlfriend', 'spouse'), 0.9382742871773593)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised('wife')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d9c1b6f9e64112a2279f92df6c7dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('information', 'wisdom'), 0.9403342342072523),\n",
       " (('information', 'learn'), 0.9350064193175482),\n",
       " (('educated', 'information'), 0.9344299845410369),\n",
       " (('information', 'intellectual'), 0.9309315443680511),\n",
       " (('education', 'information'), 0.9307278820220717),\n",
       " (('awareness', 'information'), 0.9307015034571826),\n",
       " (('information', 'scholar'), 0.9306620303940811),\n",
       " (('information', 'science'), 0.9305924314684961),\n",
       " (('information', 'intelligence'), 0.9300627381165681),\n",
       " (('information', 'skill'), 0.9293827675453067)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised('knowledge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f6ab027549472dbe46bbf1bda581f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('independence', 'liberty'), 0.9471041375203225),\n",
       " (('independence', 'liberation'), 0.9449252796240266),\n",
       " (('liberation', 'liberty'), 0.9407391445453362),\n",
       " (('escape', 'liberty'), 0.9402727088282272),\n",
       " (('independent', 'liberty'), 0.9388423946595881),\n",
       " (('independent', 'liberation'), 0.9378218136121038),\n",
       " (('choice', 'liberation'), 0.9369603627095202),\n",
       " (('autonomy', 'liberty'), 0.9364636709347575),\n",
       " (('liberty', 'release'), 0.9361554940410225),\n",
       " (('choice', 'liberty'), 0.9354926776655279)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised('freedom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b68d26846c456e9329825e2766d85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('league', 'play'), 0.9373357770650107),\n",
       " (('play', 'team'), 0.9367463606994575),\n",
       " (('match', 'player'), 0.9348914278870476),\n",
       " (('league', 'player'), 0.9341582798038441),\n",
       " (('play', 'player'), 0.9335779108745395),\n",
       " (('player', 'team'), 0.9318594819907428),\n",
       " (('play', 'tournament'), 0.9313146776902258),\n",
       " (('player', 'war'), 0.9309509363047301),\n",
       " (('match', 'play'), 0.9303957675266781),\n",
       " (('battle', 'player'), 0.9302399414236945)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised('game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef251528534c41df8304718625d87d3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('green', 'purple'), 0.9172280997456148),\n",
       " (('green', 'silver'), 0.916946225236841),\n",
       " (('purple', 'sky'), 0.9162274410273579),\n",
       " (('green', 'sky'), 0.9151894648560139),\n",
       " (('green', 'grey'), 0.9150919206251926),\n",
       " (('purple', 'white'), 0.9146052188664905),\n",
       " (('black', 'yellow'), 0.9143422438375535),\n",
       " (('black', 'green'), 0.9143011105653037),\n",
       " (('green', 'navy'), 0.913759303124728),\n",
       " (('navy', 'yellow'), 0.9135725244694811)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c6e8971ca944e08f04d2ce2d9702cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(('god', 'royal'), 0.9399845404515973),\n",
       " (('crown', 'god'), 0.9360121863710793),\n",
       " (('god', 'queen'), 0.9360081006340474),\n",
       " (('god', 'ruling'), 0.9345334313453474),\n",
       " (('lad', 'royal'), 0.9337056137410812),\n",
       " (('master', 'royal'), 0.9334969644136822),\n",
       " (('he', 'royal'), 0.932993474817868),\n",
       " (('royal', 'ward'), 0.9329218687061671),\n",
       " (('leader', 'royal'), 0.9328377258280323),\n",
       " (('royal', 'son'), 0.9326452684950428)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revised('king')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a58f2b50cba0e3ef60ddaac0060fcc6c1f1afd3fbbcd44f07b68475f7ee4549"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('aca': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
