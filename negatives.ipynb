{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Mikolov Negatives'\n",
    "If we take the vector of king, subtract the vector of man, and add the vector of woman, how close are we to the vector of queen?\n",
    "This notebook will implement a function to allow smooth testing of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "import sentencepiece    # necessary for proper t5 init.\n",
    "from transformers import T5Tokenizer, T5EncoderModel, GPT2Tokenizer, OPTModel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# api key set in conda env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab\n",
    "Now expanded to the Oxford 5000, plus relevant test words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "with open('./expanded_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        vocab.append(line.strip())\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3\n",
    "Vectors are normalized. Produced by https://arxiv.org/abs/2201.10005. Note: \"Our models achieved new state-of-the-art results in linear-probe classification, text search and code search. We find that our models **underperformed on sentence similarity tasks and observed unexpected training behavior with respect to these tasks**.\" (emphasis mine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved embeddings from GPT-3 Ada\n",
    "# Ada embeds: 1024 dims\n",
    "# Babbage load included below as comment.\n",
    "\"\"\"\n",
    "# Babbage embeds: 2048 dims\n",
    "bab_embeds = []\n",
    "with open(u'/gpfs/fs1/home/mbarlow6/Desktop/Conceptual-Analysis/barlow/gpt/gpt_babbage.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        bab_embeds.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "model_bab = dict(zip(vocab, bab_embeds))\n",
    "\"\"\"\n",
    "ada_embeds = []\n",
    "with open(u'./gpt/gpt_ada.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        ada_embeds.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "model_gpt = dict(zip(vocab, ada_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting new embeddings from OpenAI\n",
    "def gpt_embed(text, engine='text-similarity-ada-001'):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return openai.Embedding.create(input=[text], engine=engine)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT\n",
    "OPT, like GPT-3, is a Decoder-only Transformer. BERT is encoder only, and T5 is encoder-decoder, making use of both. Likewise, getting embeddings from OPT is a *little* less complicated, as there is only one part of the architecture we look to for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('facebook/opt-1.3b', cache_dir='/scratch/mbarlow6/cache')\n",
    "model_opt_raw = OPTModel.from_pretrained('facebook/opt-1.3b', cache_dir='/scratch/mbarlow6/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_embeds = []\n",
    "with open(u'./opt/1_3B.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        opt_embeds.append([float(x) for x in line.strip().split()])\n",
    "model_opt = dict(zip(vocab, opt_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_embed(text, tokenizer=gpt2_tokenizer, model=model_opt_raw, debug=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    if debug:\n",
    "        print('Tokens Requested:')\n",
    "        print(tokenizer.batch_decode(inputs.input_ids[0]))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = torch.squeeze(outputs.last_hidden_state, dim=0)\n",
    "    # compare with:\n",
    "    # final_embed = np.array(embeddings[1])\n",
    "    # if embeddings.shape[0] > 2:\n",
    "    #     for next_emb in embeddings[2:]:\n",
    "    #         final_embed += np.array(next_emb)\n",
    "    #     final_embed /= embeddings.shape[0] - 1\n",
    "    # return final_embed\n",
    "    return np.array(torch.mean(embeddings, dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5\n",
    "Here is our encoder-decoder model. I will extract embeddings from the encoder only, as per results from https://arxiv.org/pdf/2108.08877.pdf. Note: \"When mean pooling is applied to the T5’s encoder outputs, it greatly outperforms the average embeddings of BERT. Notably, even without fine-tuning, the average embeddings of the T5’s encoder-only outputs outperforms SimCSE-RoBERTa, which is fine-tuned on NLI datase.\"\n",
    "\n",
    "Seeing as I amd doing no fine tuning, and mean pool OPT decoder outputs, I will do the same with T5's **encoder** outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-large', cache_dir='/scratch/mbarlow6/cache')\n",
    "model_t5_raw = T5EncoderModel.from_pretrained('t5-large', cache_dir='/scratch/mbarlow6/cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_embed(text, tokenizer=t5_tokenizer, model=model_t5_raw, debug=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    if debug:\n",
    "        print('Tokens Requested:')\n",
    "        print(tokenizer.batch_decode(inputs.input_ids[0]))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = torch.squeeze(outputs.last_hidden_state, dim=0)\n",
    "    return np.array(torch.mean(embeddings, dim=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aca2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50d097db58378ea4fc243263c82ac89485e39b9e188e1c6006c60e88b9913d6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
