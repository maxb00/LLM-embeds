{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Mikolov Negatives'\n",
    "If we take the vector of king, subtract the vector of man, and add the vector of woman, how close are we to the vector of queen?\n",
    "This notebook will implement a function to allow smooth testing of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import openai\n",
    "import numpy as np\n",
    "\n",
    "import sentencepiece    # necessary for proper t5 init.\n",
    "from transformers import T5Tokenizer, T5EncoderModel, GPT2Tokenizer, OPTModel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# api key set in conda env.\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab\n",
    "Now expanded to the Oxford 5000, plus relevant test words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "with open('./expanded_vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        vocab.append(line.strip())\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3\n",
    "Vectors are normalized. Produced by https://arxiv.org/abs/2201.10005. Note: \"Our models achieved new state-of-the-art results in linear-probe classification, text search and code search. We find that our models **underperformed on sentence similarity tasks and observed unexpected training behavior with respect to these tasks**.\" (emphasis mine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading saved embeddings from GPT-3 Ada\n",
    "# Ada embeds: 1024 dims\n",
    "# Babbage load included below as comment.\n",
    "\"\"\"\n",
    "# Babbage embeds: 2048 dims\n",
    "bab_embeds = []\n",
    "with open(u'/gpfs/fs1/home/mbarlow6/Desktop/Conceptual-Analysis/barlow/gpt/gpt_babbage.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        bab_embeds.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "model_bab = dict(zip(vocab, bab_embeds))\n",
    "\"\"\"\n",
    "ada_embeds = []\n",
    "with open(u'./gpt/gpt_ada.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        ada_embeds.append([float(x) for x in line.strip().split()])\n",
    "\n",
    "model_gpt = dict(zip(vocab, ada_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for getting new embeddings from OpenAI\n",
    "def gpt_embed(text, engine='text-similarity-ada-001'):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return openai.Embedding.create(input=[text], engine=engine)['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPT\n",
    "OPT, like GPT-3, is a Decoder-only Transformer. BERT is encoder only, and T5 is encoder-decoder, making use of both. Likewise, getting embeddings from OPT is a *little* less complicated, as there is only one part of the architecture we look to for embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1c617db72f41eab88ad4f9aa2958b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae6114f39b74824b9d9c49c740c2017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e900411c1894ec58712e9c7947d0873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/441 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b726a411b994d648401da29dd4e1ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/685 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f305d81e68ad4358b381c160f1d8c457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8870fca67644e2bce0e55f0a83949f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/opt-1.3b were not used when initializing OPTModel: ['lm_head.weight', 'model.decoder.final_layer_norm.weight', 'model.decoder.final_layer_norm.bias']\n",
      "- This IS expected if you are initializing OPTModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing OPTModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('facebook/opt-1.3b', cache_dir='/scratch/mbarlow6/.cache')\n",
    "model_opt_raw = OPTModel.from_pretrained('facebook/opt-1.3b', cache_dir='/scratch/mbarlow6/.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_embeds = []\n",
    "with open(u'./opt/1_3B.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        opt_embeds.append([float(x) for x in line.strip().split()])\n",
    "model_opt = dict(zip(vocab, opt_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_embed(text, tokenizer=gpt2_tokenizer, model=model_opt_raw, debug=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    if debug:\n",
    "        print('Tokens Requested:')\n",
    "        print(tokenizer.batch_decode(inputs.input_ids[0]))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = torch.squeeze(outputs.last_hidden_state, dim=0)\n",
    "    return np.array(torch.mean(embeddings[1:], dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T5\n",
    "Here is our encoder-decoder model. I will extract embeddings from the encoder only, as per results from https://arxiv.org/pdf/2108.08877.pdf. Note: \"When mean pooling is applied to the T5’s encoder outputs, it greatly outperforms the average embeddings of BERT. Notably, even without fine-tuning, the average embeddings of the T5’s encoder-only outputs outperforms SimCSE-RoBERTa, which is fine-tuned on NLI datase.\"\n",
    "\n",
    "Seeing as I amd doing no fine tuning, and mean pool OPT decoder outputs, I will do the same with T5's **encoder** outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0b67865255446daca2eb93c130226e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f872d255515433d8c4aa7f161d260b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbarlow6/.local/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd92a220f3a84d8aabb50f4fe5a654df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at t5-large were not used when initializing T5EncoderModel: ['decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.final_layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight']\n",
      "- This IS expected if you are initializing T5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing T5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of T5EncoderModel were not initialized from the model checkpoint at t5-large and are newly initialized: ['encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-large', cache_dir='/scratch/mbarlow6/.cache')\n",
    "model_t5_raw = T5EncoderModel.from_pretrained('t5-large', cache_dir='/scratch/mbarlow6/.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_embeds = []\n",
    "with open('./t5/t5large.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        t5_embeds.append([float(x) for x in line.strip().split()])\n",
    "model_t5 = dict(zip(vocab, t5_embeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_embed(text, tokenizer=t5_tokenizer, model=model_t5_raw, debug=False):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    if debug:\n",
    "        print('Tokens Requested:')\n",
    "        print(tokenizer.batch_decode(inputs.input_ids[0]))\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = torch.squeeze(outputs.last_hidden_state, dim=0)\n",
    "    return np.array(torch.mean(embeddings, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "Here I will define some functions for the purpose of the investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive(words, model='gpt'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        words: iterable\n",
    "        model: 'gpt', 'opt', or 't5'\n",
    "    Returns:\n",
    "        Positive (summed vectors) of word embeddings of a given list of words from the specified model. Defaults to GPT-3.\n",
    "    \"\"\"\n",
    "    if isinstance(words, str):\n",
    "        print(f\"You requested the positive of the string \\\"{words}\\\". Did you mean [\\\"{words}\\\"]?\")\n",
    "\n",
    "    out = 0\n",
    "    for token in words:\n",
    "        # convert token to string\n",
    "        word = str(token)\n",
    "        # do model check - least intensive operation to repeat\n",
    "        if model.lower() == 'gpt':\n",
    "            # look for token in cached GPT embeds\n",
    "            if word in model_gpt:\n",
    "                ex = model_gpt[word]  # ex for \"extracted\"\n",
    "            # if not found, query API\n",
    "            else:\n",
    "                ex = gpt_embed(word)\n",
    "                model_gpt[word] = ex\n",
    "        elif model.lower() == 'opt':\n",
    "            if word in model_opt:\n",
    "                ex = model_opt[word]\n",
    "            else:\n",
    "                # squeeze!\n",
    "                ex = opt_embed(word)\n",
    "                model_opt[word] = ex\n",
    "        elif model.lower() == 't5':\n",
    "            if word in model_t5:\n",
    "                ex = model_t5[word]\n",
    "            else:\n",
    "                ex = t5_embed(word)\n",
    "                model_t5[word] = ex\n",
    "        else:\n",
    "            raise ValueError('Please provide either gpt, opt, or t5 as a model choice.')\n",
    "\n",
    "        # construct positive\n",
    "        if isinstance(out, int):\n",
    "            out = np.array(ex).reshape(1, -1)\n",
    "        else:\n",
    "            out += np.array(ex).reshape(1, -1)\n",
    "            \n",
    "    return out if not isinstance(out, int) else np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(words, target, vec=False, model='gpt'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        words: iterable or vector   -> Items to be combined into a positive and compared,\n",
    "                                       or already constructed vector of matching dimensions.\n",
    "        target: str     -> single term to calulate similarity to.\n",
    "        vec: bool       -> true if 'words' is a vector\n",
    "        model: str      -> 'gpt', 'opt', or 't5'\n",
    "    Returns:\n",
    "        The cosine similarity of the words vector and target term in specified model.\n",
    "    \"\"\"\n",
    "    # get phrase\n",
    "    phrase = words\n",
    "    if not vec:\n",
    "        if isinstance(words, str):\n",
    "            phrase = positive([words], model)\n",
    "        else:\n",
    "            phrase = positive(words, model)\n",
    "    \n",
    "    # get target\n",
    "    target = positive([target], model)\n",
    "\n",
    "    return cosine_similarity(phrase, target)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative(start, det, add, end, model='gpt'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        start: str  -> starting word\n",
    "        det: str    -> word to subtract from start\n",
    "        add: str    -> word to add to get new direction\n",
    "        end: str    -> target word\n",
    "        model: str  -> gpt, opt, or t5.\n",
    "    Returns:\n",
    "        The cosine similarity between <end> and <start> - <det> + <add>.\n",
    "    \"\"\"\n",
    "    A = positive([start], model)\n",
    "    B = positive([det], model)\n",
    "    C = positive([add], model)\n",
    "    D = positive([end], model)\n",
    "    neg = (A - B) + C\n",
    "    return cosine_similarity(neg, D)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mikolov(start, less, more, target):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        start: str  -> starting word\n",
    "        det: str    -> word to subtract from start\n",
    "        add: str    -> word to add to get new direction\n",
    "        end: str    -> target word\n",
    "    Returns:\n",
    "        None. Wraps negative for each model we have to test.\n",
    "    \"\"\"\n",
    "    print(*[start, less, more], sep=', ', end='')\n",
    "    print(f\" -> {target}\")\n",
    "    for model in ['gpt', 'opt', 't5']:\n",
    "        print(f\"model: {model}\")\n",
    "        print(f\"score: {negative(start, less, more, model)}\")\n",
    "        print(f\"benchmark: {start} -> {target} = {calculate_similarity([start], target, model=model)}\")\n",
    "        print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "Main Categories identified: *opposite-gender*, *capitol-of*, *pluralization*, *adjective-scale*, *possesion*, and *tense*.\n",
    "\n",
    "Please refer to https://arxiv.org/pdf/1509.01692.pdf and https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/rvecs.pdf for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* opposite-gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king, man, woman -> queen\n",
      "model: gpt\n",
      "score: 0.7378115578440716\n",
      "benchmark: king -> queen = 0.9117405424813445\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7957717588520916\n",
      "benchmark: king -> queen = 0.6519601615672634\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7511311209215747\n",
      "benchmark: king -> queen = 0.5005843823222568\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('king', 'man', 'woman', 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chairman, man, woman -> chairwoman\n",
      "model: gpt\n",
      "score: 0.6522159143876429\n",
      "benchmark: chairman -> chairwoman = 0.9445721548901769\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7059410113916196\n",
      "benchmark: chairman -> chairwoman = 0.9417800696634807\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.6497875212009107\n",
      "benchmark: chairman -> chairwoman = 0.6183062413573323\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('chairman', 'man', 'woman', 'chairwoman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brother, male, female -> sister\n",
      "model: gpt\n",
      "score: 0.7596375085364417\n",
      "benchmark: brother -> sister = 0.9134060809522063\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8316455619512485\n",
      "benchmark: brother -> sister = 0.557895862264566\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7632233058668813\n",
      "benchmark: brother -> sister = 0.7528198508095869\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('brother', 'male', 'female', 'sister')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stallion, male, female -> mare\n",
      "model: gpt\n",
      "score: 0.6962794443000064\n",
      "benchmark: stallion -> mare = 0.8475974889192053\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7506368283946538\n",
      "benchmark: stallion -> mare = 0.5576398415985386\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7054738074979054\n",
      "benchmark: stallion -> mare = 0.31265633795208364\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('stallion', 'male', 'female', 'mare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* capitol-of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madrid, Spain, France -> Paris\n",
      "model: gpt\n",
      "score: 0.7393247629269616\n",
      "benchmark: Madrid -> Paris = 0.9007781858064563\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8171097543563783\n",
      "benchmark: Madrid -> Paris = 0.5303939580917358\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7522346421892213\n",
      "benchmark: Madrid -> Paris = 0.7242726683616638\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('Madrid', 'Spain', 'France', 'Paris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pluralization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars, car, apple -> apples\n",
      "model: gpt\n",
      "score: 0.8042591015676499\n",
      "benchmark: cars -> apples = 0.8524972988346033\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8708407098948878\n",
      "benchmark: cars -> apples = 0.5699345469474792\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7876204873860704\n",
      "benchmark: cars -> apples = 0.6409047842025757\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('cars', 'car', 'apple', 'apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years, year, law -> laws\n",
      "model: gpt\n",
      "score: 0.7852276945566117\n",
      "benchmark: years -> laws = 0.8483212083512726\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8493390486675807\n",
      "benchmark: years -> laws = 0.5232529640197754\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7946566917630429\n",
      "benchmark: years -> laws = 0.7154074907302856\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('years', 'year', 'law', 'laws')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* adjective-scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hot, warm, cool -> cold\n",
      "model: gpt\n",
      "score: 0.7819205476154103\n",
      "benchmark: hot -> cold = 0.8576111115834552\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8466620250197867\n",
      "benchmark: hot -> cold = 0.5924510794233862\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7903440844728845\n",
      "benchmark: hot -> cold = 0.6201469350799498\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('hot', 'warm', 'cool', 'cold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best, good, bad -> worst\n",
      "model: gpt\n",
      "score: 0.7502848923165245\n",
      "benchmark: best -> worst = 0.8677750042777197\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8133568359441687\n",
      "benchmark: best -> worst = 0.8731156467209791\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7641626398489444\n",
      "benchmark: best -> worst = 0.46554383381387376\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('best', 'good', 'bad', 'worst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* possession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city's, city, bank -> bank's\n",
      "model: gpt\n",
      "score: 0.8100800352663959\n",
      "benchmark: city's -> bank's = 0.8612663210375753\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8631198519596566\n",
      "benchmark: city's -> bank's = 0.6846699714660645\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.8080202576243289\n",
      "benchmark: city's -> bank's = 0.7735621929168701\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('city\\'s', 'city', 'bank', 'bank\\'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine, me, you -> yours\n",
      "model: gpt\n",
      "score: 0.8114813212545702\n",
      "benchmark: mine -> yours = 0.9033465234916255\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.880973468945707\n",
      "benchmark: mine -> yours = 0.5635010564792599\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.8036020348017502\n",
      "benchmark: mine -> yours = 0.46227390929504036\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('mine', 'me', 'you', 'yours')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* verb-source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walking, legs, teeth -> chewing\n",
      "model: gpt\n",
      "score: 0.7040879899569987\n",
      "benchmark: walking -> chewing = 0.8454043336269507\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7603399214774956\n",
      "benchmark: walking -> chewing = 0.3978073897494764\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7020406968955835\n",
      "benchmark: walking -> chewing = 0.4715649425101859\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('walking', 'legs', 'teeth', 'chewing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk, legs, teeth -> chew\n",
      "model: gpt\n",
      "score: 0.7232827264293642\n",
      "benchmark: walk -> chew = 0.845130940848593\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.7858758351719928\n",
      "benchmark: walk -> chew = 0.403867014311146\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7280116643353497\n",
      "benchmark: walk -> chew = 0.5056241362847337\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('walk', 'legs', 'teeth', 'chew')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sailing, boat, car -> driving\n",
      "model: gpt\n",
      "score: 0.7649509877119995\n",
      "benchmark: sailing -> driving = 0.8619133991236356\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8230902797244916\n",
      "benchmark: sailing -> driving = 0.35207847641778717\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.7930588916368582\n",
      "benchmark: sailing -> driving = 0.6732577969081711\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('sailing', 'boat', 'car', 'driving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sail, boat, car -> drive\n",
      "model: gpt\n",
      "score: 0.7697334127739649\n",
      "benchmark: sail -> drive = 0.843451216162298\n",
      "-------------------------------------------------------\n",
      "model: opt\n",
      "score: 0.8280892167138598\n",
      "benchmark: sail -> drive = 0.30502673815257786\n",
      "-------------------------------------------------------\n",
      "model: t5\n",
      "score: 0.8083683579829373\n",
      "benchmark: sail -> drive = 0.6057842568936658\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mikolov('sail', 'boat', 'car', 'drive')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1a58f2b50cba0e3ef60ddaac0060fcc6c1f1afd3fbbcd44f07b68475f7ee4549"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('aca': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50d097db58378ea4fc243263c82ac89485e39b9e188e1c6006c60e88b9913d6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
